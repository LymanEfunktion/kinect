\chapter{Kinect--Framework}
\label{chap:Kinect}

\section{Microsoft Kinect SDK}
% Auflistung der Bereitgestellten Funktionen und Umfang des SDK-Toolkits

% \footnote{Microsoft Corporation (2012) \href{http://msdn.microsoft.com/en-us/library/hh973075.aspx}{\textit{DataStreams}} msdn.microsoft.com, Abgerufen Januar 03, 2013}

Das Kinect SDK von Microsoft stellt, wie zuvor bereits erw\"ahnt, die technische Schnittstelle zur Kinect zur Verf\"ugung. 
Dies sind zum einen die Programmierschnittstellen in den Sprachen C++, C\# und VB .net also auch die ben\"otigten Treiber 
und \glslink{Runtime Library}{Runtime Libraries}, die die Kommunikation mit dem Ger\"at erm\"oglichen. 
In der nachfolgenden Abbildung ist der Aufbau des SDK abgebildet.
\par\smallskip 
\begin{figure}[htb]
\centering
\includegraphics[width=0.8\textwidth]{img/04kapitel/sdk.png}
\caption[SDK Architektur]{SDK Architektur (Quelle: Microsoft Corp.\footnotemark[1])}
\label{fig:SDK Architecture}
\end{figure}
\footnotetext[1]{Microsoft Corp. (2012) \href{http://msdn.microsoft.com/en-us/library/jj131023.aspx}{\textit{SDK Architektur}} msdn.microsoft.com, Abgerufen Januar 03, 2013}
\par\smallskip 
Die Ebene 3 enth\"alt die Programmierschnittstelle. Mittels der \glslink{NUI}{NUI} \glslink{API}{API} kann auf die 
Datenstr\"ome, die die Kinect liefert zugegriffen werden. Von der Kinect werden hier vier Datenstr\"ome\footnotemark[2] geliefert: 
\begin{itemize}
  \item AudioStrom
  \item Farbstrom
  \item Tiefenstrom
  \item Infrarotstrom
\end{itemize}
\footnotetext[2]{Microsoft Corp. (2012) \href{http://msdn.microsoft.com/en-us/library/hh973075.aspx}{\textit{DataStreams}} msdn.microsoft.com, Abgerufen Januar 03, 2013}
\par\smallskip 
Auf Basis dieser Datensr\"ome kann eine Erkennung von Personen, Gesten und Sprachkommandos realisiert werden.
Dies ist jedoch nicht zwingend notwendig, da hier durch die M\"oglichkeit des Zugriffs auf einen Skelettstrom bereits, 
ohne diesen Transformationsschritt von Rohdaten zu einem Model, auf die Koordinaten eines Modells des menschlichen K\"orpers 
zugegriffen werden kann. Diese Komponente kann bis zu 2 Personen erkennen und die Modelle dieser Personen liefern\footnotemark[3].
Das Modell basiert auf 20 Punkten, die bestimmt K\"orperteile und -regionen abbilden. Dieses Modell ist in Abbildung \ref{fig:skeleton} zu sehen.
\par\smallskip 
\begin{figure}[htb]
\centering
\includegraphics[width=0.8\textwidth]{img/04kapitel/skeleton.png}
\caption[Skeleton]{Skeleton (Quelle: Microsoft Corp.\footnotemark[3])}
\label{fig:skeleton}
\end{figure}
\footnotetext[3]{Microsoft Corp. (2012) \href{http://msdn.microsoft.com/en-us/library/jj131025.aspx}{\textit{Tracking Users with Kinect Skeletal Tracking}} msdn.microsoft.com, Abgerufen Januar 03, 2013}
\newpage
Auf dieser Basis wird es schon relativ leicht m\"oglich eine Gestensteuerung zu entwickeln. Weitere Beispiele f\"ur das Tracking bilden die 
Ausgabe des Kinect Explorer\footnotemark[4], einem Beispiel welches Teil des SDK ist und einer Visualisierung mittels \glslink{GEF}{GEF} in der 
Anwendung die im Rahmen dieser Arbeit entwickelt wird. In \ref{fig:kinectexplorer} ist die Visualisierung der Punkte im Kinect Explorer zu sehen, 
in \ref{fig:gef} die Darstellung in mit dem \glslink{GEF}{Graphical Editing Framework}.
\footnotetext[4]{Microsoft Corp. (2012) \href{http://msdn.microsoft.com/en-us/library/hh855378}{\textit{Kinect Explorer}} msdn.microsoft.com, Abgerufen Januar 03, 2013}
\par\smallskip 
\begin{figure}[htb]
\centering
\includegraphics[width=0.8\textwidth]{img/04kapitel/kinectexplorer.png}
\caption[Kinect Explorer]{Kinect Explorer\footnotemark[4]}
\label{fig:kinectexplorer}
\end{figure}
\begin{figure}[!]
\centering
\includegraphics[width=0.8\textwidth]{img/04kapitel//gefeditor.png}
\caption[GEF Editor]{GEF Editor}
\label{fig:gef}
\end{figure}
\newpage
Au\ss erdem ist es auch unter Verwendung des SDK in mindestens Version 1.5 und einer \textit{Kinect for Windows} m\"oglich 
ein Gesicht und dessen Bewegungen zu erfassen\footnotemark[5]. Diese Funktion wird im ersten Teil dieser Arbeit jedoch noch keine Anwendung finden.
\footnotetext[5]{Microsoft Corp. (2012) \href{http://msdn.microsoft.com/en-us/library/jj130970.aspx}{\textit{Face Tracking}} msdn.microsoft.com, Abgerufen Januar 03, 2013}
\par\smallskip 
Zur Spracherkennung muss ebenfalls nicht notwendigerwei\ss e direkt der Audiostrom der Kinect analysiert werden. Mittels einer Speechengine kann auf Basis 
einer durch den Entwickler definierten Grammatik Sprache erkannt werden. Der Entwickler wird dann \"uber erkannte Kommandos mittels Events benachrichtigt. 

\section{Java Frameworks}
% Nutzung von Java begr\"unden etc.

Da die Entwicklung mit Java durchgef\"uhrt werden soll ist es notwendig einen \glslink{Wrapper}{Wrapper} f\"ur das Kinect SDK zu verwenden.
Hierzu existieren bereits diverse Frameworks die genau das erm\"oglichen.
Nachfolgend werden drei dieser Frameworks betrachtet und deren Nutzbarkeit im Rahmen dieser Arbeit evaluiert.
Abschlie\ss end wird ein Framework ausgew\"ahlt auf dessen Basis die Umsetzung dieser Arbeit erfolgen soll.
\par\smallskip 
Ziel dieser Arbeit ist die Umsetzung einer Gesten- und Sprachsteuerung. Daher sollte ein m\"oglichst einfacher Zugang zum Skelettstrom und der 
Spracherkennungskomponennte des Kinect SDK vorhanden sein. Eine Eigenentwicklung dieser Funktionen w\"urde den Rahmen dieser Arbeit bei weitem \"uberschreiten.


\subsection{OpenNI}
% Einf\"uhrende Worte zu Framework: Initiator und Startzeitpunkt des Projekts, aktuelle Version

\subsubsection{Beschreibung}
OpenNI\footnotemark[7] ist der Name eines Industriekonsortiums dessen Ziel es ist, die Entwicklung und Standardisierung von Software und Hardware 
im Bereich der Natural User Interfaces.
Es wurde im November 2010 ins Leben gerufen und setzt sich aus verschiedenen großen Unternehmen zusammen. Dazu geh\"ort beispielsweise Primesense, 
welches selbst solche Ger\"ate entwickelt und vertreibt oder auch ASUS, welche in Kooperation mit Primesense die Xtion Pro\footnotemark[9] entwickelt haben und vertreiben.
Zusammen formen diese unter dem Namen OpenNI eine Non-Profit-Organisation.

\footnotetext[6]{OpenNI \href{http://www.openni.org/}{\textit{Home}} openni.org, Abgerufen Januar 04, 2013}
\footnotetext[7]{OpenNI \href{http://www.openni.org/organization/}{\textit{Organization}} openni.org, Abgerufen Januar 04, 2013}
\footnotetext[8]{OpenNI \href{http://www.openni.org/about/}{\textit{About}} openni.org, Abgerufen Januar 04, 2013}
\footnotetext[9]{Asus (Mai 2011) \href{http://www.asus.de/Multimedia/Motion_Sensor/Xtion_PRO/}{\textit{Xtion Pro}} aus.de, Abgerufen Januar 04, 2013}

\subsubsection{Technische Daten}

Durch OpenNI wird ein SDK und eine Plattform zur Verf\"ugung gestellt, mit der eine Verbindung mit verschiedenen Ger\"aten m\"oglich ist. Zu sehen ist der Aufbau in \ref{fig:opennisdki}.
Das SDK stellt eine Schnittstelle zu den grunds\"atzlichen Sensoren der Hardware und den davon generierten Datenstr\"omen dar.
Einzig der Audiostrom wird zum jetztigen Zeitpunkt noch nicht nutzbar.
Durch den Einsatz von \textit{Middleware Libraries} k\"onnen abstraktere Funktionen, wie das Tracking eines Skeletts abgebildet werden. Ein Beispiel 
hierf\"ur ist die Middleware Nite 2\footnotemark[10] von Primesense. Das SDK eignet sich grunds\"atzlich zur Nutzung verschiedener Ger\"ate, 
sofern Treiber verf\"ugbar sind, ist also nicht auf die Kinect festgelegt.
Eigene Anwendungen lassen sich mittels der API in C++ entwickeln. Außerdem werden Wrapper Java und C\# bereitgestellt.

Zugriff auf das Mikrofonarray ist jedoch nicht gegeben und muss vom Benutzer selbst implementiert werden.

\begin{figure}[htb]
\centering
\includegraphics[width=0.4\textwidth]{img/04kapitel/OpenNI2_Architecture2.png}
\caption[Kinect Explorer]{Architektur des OpenNI SDK\footnotemark[8]}
\label{fig:opennisdk}
\end{figure}
\footnotetext[10]{OpenNI \href{http://www.openni.org/files/nite/}{\textit{Nite 2}} openni.org, Abgerufen Januar 04, 2013}

\subsubsection{Analyse der Anwendbarkeit}



\subsection{OpenKinect}

\subsubsection{Beschreibung}

OpenKinect ist eine Open Source Community, die sich aus Personen zusammensetzt deren Interesse in der Entwicklung rund um die Kinect und ähnlichen Geräten liegt.
Diese Community entwickelt derzeitig die Software lifreenect

\subsubsection{Technische Daten}

OpenKinect ist in C geschrieben, stellt jedoch Wrapper für viele weitere Sprachen bereit\footnotemark[12], darunter auch Java. Außerdem sind Treiber für die Kinect enthalten.

\footnotetext[11]{OpenKinect \href{http://openkinect.org/wiki/Main_Page}{\textit{OpenKinect Mainpage}} openkinect.org, Abgerufen Januar 05, 2013}
\footnotetext[11]{Abschnitt Wrapper \href{http://openkinect.org/wiki/Main_Page}{\textit{OpenKinect Mainpage}} openkinect.org, Abgerufen Januar 05, 2013}

\subsubsection{Analyse der Anwendbarkeit}

Dieses Projekt bietet ebenfalls die Möglichkeit mittels Java auf die Kinect zuzugreifen. 


\subsection{jnect}
\label{subsec:jnect}

\subsubsection{Beschreibung}

jnect ist ein Plugin f\"ur die Eclipse-Plattform. Es macht Funktionen der Kinect f\"ur Eclipse-basierte Anwendungen und Plugins nutzbar. 
Im Gegensatz zu OpenNI und OpenKinect stellt jnect keine eigene Schnittstelle zur Kinect zur Verf\"ugung. Es ist lediglich ein Wrapper f\"ur die Skeleton-Tracking und Speech Recognition Engine des Kinect for Windows SDK. 

\subsubsection{Technische Daten}

Das Project besitzt einen Wrapper f\"ur die genutzten Funktionen des Kinect SDK. Die durch jnect genutzen Funktionen sind das Skeleton-Tracking 
und die Sprachengine. Das Skeleton der Kinect wird innerhalb von jnect in einem Modell des \gls{EMF} gespeichert.

\subsubsection{Analyse der Anwendbarkeit}

Auch dieses Projekt ist durch die Implementierung in Java schon einmal grundsätzlich als nutzbar einzustufen. Die Datenstrome 
der Sensoren werden jedoch nicht zur Verfügung gestellt. Das stellt aber kein Problem dar, da für diese Arbeit Gesten und Sprachbefehle 
erfasst werden sollen, was durch die Verfügbarkeit des Skelett-Modells und den Zugang zur Sprachengine gegeben sind.

\subsection{Nutzwertanalyse}
%Nutzwertanalyse aller drei Modelle im Vergleich

\begin{figure}[htb]
\centering
\includegraphics[width=0.8\textwidth]{img/04kapitel/nutzwert.png}
\caption[Nutzwertanalyse Frameworks]{Nutzwertanalyse der verwendbaren Frameworks}
\label{fig:nutzwert}
\end{figure}


\subsection{Analyseergebnis}
%Resultat: jnect \ldots das beste vom besten

Aufgrund der guten Eignung wird für die Umsetzung dieser Arbeit auf das Projekt jnect gesetzt.
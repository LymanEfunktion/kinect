\chapter{Modelle zur Gesten- und Spracherkennung}
\label{chap:Modelle}
% Einf\"uhrende Worte
Es existieren diverese Verfahren zur Gesten- und Spracherkennung. Die bekanntesten Vertreter sind \glspl{NeuroNetz}, \gls{DTW} und \gls{HMM}.
\newline
Im Folgenden werden dennoch kurz die diversen Eigenschaften und Algorithmen hinter den weiteren Modell er\"ortert, um eine fundierte Entscheidung \"uber die Auswahl eines dieser Modelle f\"ur diese Arbeit und das zu erarbeitende Programm zu treffen.
 

\section{Dynamic Time Warping}
\gls{DTW} ist ein Algorithmus zur Messung von \"Ahnlichkeiten zwischen einer Eingabesequenz und einem gegebenen Muster, die sich im zeitlichen Ablauf oder der Geschwindigkeit unterscheiden. Dabei w\"urden zum Bespiel die Gemeinsamkeiten im Laufmuster erkannt werden, selbst wenn eine Person in einem Video langsam l\"auft und diese Person in einer weiteren Aufnahme schneller laufen w\"urde, oder gar eine Beschleunigung oder Verlangsamung w\"ahrend des Zeitraumes der Beobachtung stattfindet.
\newline
Formalisiert versteht man unter \acrshort{DTW} eine vorlagenbasierte Erkennungstechnik auf Grundlage von dynamischer Programmierung~\cite[S.~963]{bib:hmmlee}.
Trotz der Erfolge bei Aufgaben mit kleinem Vokabular, braucht \acrshort{DTW} eine gro\ss e Anzahl an Vorlagen f\"ur ein gr\"osseres Umfeld an Variation. Weiterhin kann es keine undefinierte Muster verarbeiten.
\newline
Takahashi et al.~\cite{bib:takahashi} haben einen sogenannten \textit{spotting algorithm} vorgeschlagen 
Referenz~\cite{bib:finlay}~\cite{bib:kober}


\section{K\"unstliche neueronale Netze}

\section{Hidden Markov Model}
% Mit Zahlen und Funktionen erschlagen \ldots
% Alles aus Wiki und Books rauskotzen
Das \gls{HMM} ist ein stochastisches Modell, in dem ein System durch eine Markov-Kette mit unbeobachteten Zust\"anden modelliert wird.
Die Theorie dazu wurde von Baum~\cite{bib:hmmbaum}, 1966 ver\"offentlicht.
\newline
Der versteckte (englisch \textit{hidden}) Prozess ist eine Markov-Kette und besteht aus Zust\"anden und \"Ubergangswahrscheinlichkeiten.
Das Modell ist wie folgt definiert:

\subsubsection{Definition}
Ein \gls{HMM} $\lambda = (S, A, O, B, \pi)$ ist gegeben durch
\begin{itemize}
  \item $S = {S_1,\ldots,S_n}$ -- Menge aller Zust\"ande,
  \item $A = {a_{ij}}$ -- \"Ubergangsmatrix zwischen den Zust\"anden, wobei $a_{ij}$ die Wahrscheinlichkeit angibt, dass Zustand $S_i$ in Zustand $S_j$ gewechselt wird,
  \item $O = {O_1,\ldots,O_m}$ -- Menge der m\"oglichen Beobachtungen (\textit{Emissionen}),
  \item $B = {b_{ij}}$ -- Beobachtungsmatrix, wobei $b_{ij}$ die Wahrscheinlichkeit angibt, im Zustand $S_i$ die Beobachtung $O_j \in O$
  \item $\pi$ -- Anfangswahrscheinlichkeitsverteilung mit $\pi (i)$ Wahrscheinlichkeit, dass $S_i$ der Startzustand ist.
\end{itemize}

\subsection{Auswahl des Modells f\"ur die Arbeit}
Rabiner et al.~\cite[S.~257f]{bib:hmmrabiner}, sowie Lee und Kim~\cite[S.~961]{bib:hmmlee} sprechen von den guten Erfolgen des \gls{HMM} als stochastisches Werkzeug zur Modellierung von Gesten.
Daher wird f\"ur diese Arbeit eine Implementierung mittels \acrshort{HMM} erarbeitet.

\subsection{Diskrete Markov-Prozesse}
\label{subsec:MarkovKette}
Eine Markov-Kette ist ein \gls{StochProz}. Dabei unterscheidet man zwischen Markov-Ketten in diskreter und in stetiger Zeit. Weiter spricht man von Markov-Ketten, sofern ein diskreter Zustandsraum vorhanden ist, von \textit{Markov-Prozessen} im Allgemeinen wenn ein stetiger Zustandsraum vorliegt.
\newline
Bei einem \acrshort{HMM} werden ausschlie\ss lich diskrete Markov-Ketten verwendet, die wie folgt definiert sind.

\subsubsection{Definition}
Gegeben sei ein System, das zu jeder gegebenen Zeit $t$ beschrieben werden kann, als sich in einer Menge von $N$ verschiedenen Zust\"anden
$S_1, S_2, \ldots, S_N$ befindend. Abbildung \ref{fig:MarkovKette} zeigt eine solche Markov-Kette mit f\"unf Zust\"anden $S_1$ bis $S_5$.
\begin{figure}[htb]
\centering
\includegraphics[width=5cm]{img/markov/markov_chain.png}
\caption[Markov-Kette mit f\"unf Zust\"anden]{Markov-Kette mit f\"unf Zust\"anden \protect{($S_1$ bis $S_5$)} mit Verbindungen (Quelle: \protect{\cite{bib:hmmrabiner}})}
\label{fig:MarkovKette}
\end{figure}
In regelm\"a\ss igen diskreten Zeitabst\"anden nimmt das System eine Zustands\"anderung vor, gem\"a\ss einer Wahrscheinlichkeitsmenge, die mit dem Zustand verkn\"upft ist. Die Zeitinstanzen, die mit den Zustands\"anderungen verkn\"upft sind, werden durch $t = 1, 2, \cdots$ gekennzeichnet und der aktuelle Zustand zum Zeitpunkt $t$ als $q_t$. F\"ur den Fall, einer diskreten Markov-Kette erster Ordnung ist diese Charakterisierung ausreichend, da
\begin{equation}
\label{E:PropMarkov}
P[q_t = S_j | q_{t-1} = S_i, q_{t-2} = S_k, \cdots]= P[q_t = S_j | q_{t-1} = S_i].
\end{equation}
Weiterhin werden ausschlie\ss lich die Prozesse betrachtet, in denen die rechte Seite der Gleichung~\ref{E:PropMarkov} zeitunabh\"angig ist, was somit zur Menge der \"Ubergangswahrscheinlichkeiten $a_{ij}$ der Form
\begin{equation}
\label{E:PropTrans}
a_{ij} = P[q_t = S_j | q_{t-1} = S_i], 1 \leq i, j \leq N
\end{equation}
f\"uhrt, wobei die Zustands\"ubergangskoeffizienten folgende Eigenschaften erf\"ullen:
\begin{subequations}
\begin{eqnarray}
\label{E:MarkovProperties}
a_{ij} \geq 0 \label{E:MarkovProperties1}\\
\sum_{j = 1}^{N} a_{ij} = 1 \label{E:MarkovProperties2}
\end{eqnarray}
\end{subequations}
Ein solcher \gls{StochProz} stellt aber noch kein \gls{HMM} dar.
\newline
Um ein besseres Verst\"andnis f\"ur diese Prozesse und deren Eigenschaften zu erlangen, wird im folgenden anhand eines Beispiels aus einer Anleitung von Lawrence Rabiner~\cite{bib:hmmrabiner} n\"aher auf das Thema eingegangen.
\newline
Man betrachte ein einfaches Markov Modell, dass mittels drei Stati das Wetter beschreibt. Diese drei Zust\"ande sind folgende:
\begin{itemize}
\item[Status 1:] Regnerisch
\item[Status 2:] Bew\"olkt
\item[Status 3:] Sonnig
\end{itemize}
Es wird gefordert, dass das Wetter am Tag $t$ durch einen der drei oberen Zust\"ande beschrieben wird. Weiter wird die Matrix $A$ der Wahrscheinlichkeiten der Zustands\"uberg\"ange wie folgt definiert:
\[
\label{E:MarkovProbMatrix}
\mathbf{A} = {a_{ij}} = 
\begin{pmatrix}
0,4 & 0,3 & 0,3 \\
0,2 & 0,6 & 0,2 \\
0,1 & 0,1 & 0,8 \\
\end{pmatrix}
\]
Das Wetter am ersten Tag $( t = 1)$ sei als sonnig (Status 3) gegeben. Stellt man nun die Frage, nach der Wahrscheinlichkeit f\"ur eine Folge von Wetterzust\"anden, oder anders formuliert, f\"ur einen Wetterverlauf der n\"achsten sieben Tage, wie \enquote{sonnig, sonnig, regnerisch, regnerisch, sonnig, bew\"olkt, sonnig,\ldots}, so kann man hierzu formal eine Sequenz aus mehreren Zust\"anen betrachten. Hierzu sei die Beobachtungssequenz $O$ definiert als $O = {S_3, S_3, S_1, S_1, S_3, S_2, S_3}\,$, was mit $t = 1, 2, \cdots, 8$ \"ubereinstimmt. Die Wahrscheinlichkeit kann ausgedr\"uckt werden als,
\begin{align}
P(O|Modell) &= P[S_3, S_3, S_3, S_1, S_1, S_3, S_2, S_3| Modell] \notag \\
 &= P[S_3] \cdot P[S_3|S_3] \cdot P[S_3|S_3] \cdot P[S_1|S_3] \cdot P[S_1|S_1] \cdot P[S_3|S_1] \cdot P[S_2|S_3] \cdot P[S_3|S_2] \notag \\
 &= \pi _3 \cdot a_{33} \cdot a_{33} \cdot a_{33} \cdot a_{31} \cdot a_{11} \cdot a_{13} \cdot a_{32} \cdot a_{23}\notag \\
 &= 1 \cdot (0,8) (0,8) (0,1) (0,4) (0,3) (0,1) (0,2)\notag\\ 
 &= 1,536 \times 10^{-4}, \notag
\end{align}
wobei
\begin{align} \label{E:PropMarkovWetterPi}
\pi _i = P[q_1 = S_i]\, , & & 1 \leq i \leq N
\end{align}
die Wahrscheinlichkeit f\"ur den initialen Status darstellt.
\newline
Auch die Frage nach der Wahrscheinlichkeit wie lange das Modell in einem gegebenen und bekannten Status genau $d$ Tage verbleibt, kann mittels \gls{HMM} beantwortert werden. Dabei kann die Wahrscheinlichkeit durch die Beobachtungssequenz
\begin{equation}
O = {\underset{1}{S_i}, \underset{2}{S_i}, \underset{3}{S_i}, \cdots, \underset{d}{S_i}\, , \underset{d+1}{S_j} \ne S_i} \notag
\end{equation}
ermittelt werden:
\begin{equation}
\label{E:PropMarkovD}
P(O | Modell,\, q_1 = S_i) = (a_{ii})^{d-1}(1 - a_{ii}) = p_i(d)
\end{equation}
Die Gr\"o\ss e $p_i(d)$ ist die (diskrete) Wahrscheinlichkeitsdichtefunktion der Dauer $d$ im Status $i$. Diese ist charakteristisch f\"ur die Dauer eines Status in einer Markov-Kette. Basierend auf $p_i(d)$ kann man die erwartete Zahl der Betrachtungen (Dauer) in einem Status berechnen, unter der Voraussetzung, dass in diesem Status gestartet wird, mit
\begin{subequations}\label{E:MarkovDuration}
    \begin{alignat}{2}
      \overline{d_i} &= \sum_{d= 1}^{\infty} dp_i(d)\label{E:MarkovDuration1}\\
      &= \sum_{d = 1}^{\infty} d(a_{ii})^{d - 1} (1 - a_{ii}) = \frac{1}{1 - a_{ii}} \, . \label{E:MarkovDuration2}
    \end{alignat}
  \end{subequations}
Daraus ergeben sich die Anzahl aufeinanderfolgender Sonnentage, gem\"a\ss \, dem Modell $\frac{1}{0,2} = 5$,  die Anzahl aufeinanderfolgender bew\"olkter Tage entsprechend mit $2,5$ und die Anzahl aufeinanderfolgender Regentage mit $1,67$.

\subsection{Erweiterung auf Hidden Markov Model}
\label{subsec:HMM}
% in einzelne Abschnitte aufteilen
Um Markov Prozesse auf Probleme anwenden zu k\"onnen, in denen sich die Beobachtungen nicht auf Zustand beziehen, muss das bisher dargestellte Konzept erweitert werden. Dazu wird der Fall hinzugef\"ugt, dass eine Beobachtung durch eine Wahrscheinlichkeitsfunktion des Zustandes ausgedr\"uckt wird. Nach Rabiner~\cite{bib:hmmrabiner} besteht das resultierende Modell aus einem doppelt eingebetteten stochastischen Prozess mit einem darunterliegenden, nicht beobachtbaren(versteckten, daher \textit{hidden}), \glslink{StochProz}{stochastischen Prozess} und wird als \gls{HMM} bezeichnet.
\newline
Ein \acrshort{HMM} ist wie folgt charakterisiert:
\begin{enumerate}
\item Sei $N$ die Anzahl aller Zust\"ande im Modell, dann sind die verschiedenen Zust\"ande definiert als $S = {S_1, S_2, \cdots, S_N}$ und der Zustand zum Zeitpunkt $t$ ist definiert als $q_t$.
\item Sei $M$ die Anzahl aller verschiedenen Beobachtungssymbole pro Zustand, dann sind die individuellen Symbole definiert als $V = {v_1, v_2, \cdots, v_M}$.
\item Sei $A = {a_{ij}}$ die \"Ubergangsmatrix, wobei
\begin{align}
a_{ij} = P[q_{t+1} = S_j \mid q_t = S_i] \, , & & 1 \leq i, j \leq N \, .
\end{align}
F\"ur den speziellen Fall, dass jeder beliebige Zustand jeden beliebigen anderen Zustand in einem Schritt erreichen kann, ist $a_{ij} > 0$ f\"ur alle $i, j$. F\"ur alle weiteren Typen eines \acrshort{HMM} ist $a_{ij} = 0$ f\"ur mindestens ein $(i, j)$ Paar.
\item Sei $B = {b_j(k)}$ die Beobachtungsmatrix im Zustand $j$, wobei
\begin{align}
b_j(k) = P[v_k \,\mbox{zum Zeitpunkt} \, t \mid q_t = S_j]\, , & & 1 \leq j \leq N \, \, \, \,  \notag \\
& & \, \, 1 \leq k \leq M \, .
\end{align}
\item Sei $\pi = {\pi_i}$ die Anfangswahrscheinlichkeitsverteilung, wobei
\begin{align}
\pi_i = P [q_1 = S_i] \, , & & 1 \leq i \leq N \, .
\end{align}
\end{enumerate}
Sind entsprechende Werte f\"ur $N, M, A, B$ und $\pi$ gesetzt, so kann das \acrshort{HMM} als Generator verwendet werden, um eine Beobachtungssequenz 
\begin{equation}
O = O_1 \, O_2 \, \cdots \, O_T
\end{equation}
wie folgt zu erhalten:
\begin{enumerate}
\item W\"ahle einen Startzustand $q_1 = S_i$ entsprechend der Anfangswahrscheinlichkeitsverteilung $\pi$ .
\item Setze $t = 1$ .
\item W\"ahle $O_t = v_k$ entsprechend der Beobachtungsmatrix f\"ur den Zustand $S_i$, zum Beispiel $b_i(k)$.
\item Gehe in in einen neuen Zustand $q_{t+1} = S_j$ entsprechend der Beobachtungsmatrix f\"ur den Zustand $S_i$ \"uber, zum Beispiel $a_{ij}$.
\item Setze $t = t+ 1$; kehre zu Schritt 3 zur\"uck, falls $t < T$; beende andernfalls die Prozedur.
\end{enumerate}
Nach Rabiner~\cite[S. 5]{bib:hmmrabiner} kann diese Prozedur sowohl dazu verwendet werden, Beobachtungen zu generieren und als Modell, wie eine gegebene Beobachtungssequenz von einem entsprechendem \acrshort{HMM} erstellt wurde.
\newline
Eine vollst\"andige Spezifikation eines \acrshort{HMM} ben\"otigt die Beschreibung zweier Modellparameter ($N$ und $M$), die Spezifikation von Beobachtungssymbolen und die Beschreibung der drei Wahrscheinlichkeitsgr\"o\ss en $A, B$ und $\pi$.
Meist wird hierf\"ur die kompakte Notation
\begin{equation}
\lambda = (A, B, \pi)
\end{equation}
verwendet, um die Vollst\"andigkeit aller Paramter des Modells anzuzeigen.

\subsection[Die drei grundlegenden Probleme eines Hidden Markov Model]{Die drei grundlegenden Probleme eines Hidden Markov Model \protect{\footnote{Die Ausf\"uhrungen basieren auf den Vortr\"agen von Jack Ferguson von IDA an den Bell Laboratories}}}
Verwendet man die oben Form eines \acrshort{HMM}, die in Abschnitt~ref{subsec:HMM} beschrieben ist, so ergeben sich drei grundlegende Probleme, die vor einem Einsatz von \gls{HMM} in einer Anwendung gel\"ost werden m\"ussen. Diese lauten wie folgt:


\section{Baum-Weich-Algorithmus}
% weiter kotzen

\subsection{ToDo}
% und sch\"on aufdr\"oseln

\section{ToDo}
% eventuell weitere Punkte